from langchain_core.runnables import RunnableConfig
from langgraph.runtime import Runtime
from coze_coding_utils.runtime_ctx.context import Context
from graphs.state import (
    SplitEmailsInput, SplitEmailsOutput,
    FetchNewsInput, FetchNewsOutput,
    DeduplicateNewsInput, DeduplicateNewsOutput,
    ExtractDateInput, ExtractDateOutput,
    EnrichNewsInput, EnrichNewsOutput,
    CreateTableInput, CreateTableOutput,
    SendEmailInput, SendEmailOutput,
    SaveNewsHistoryInput, SaveNewsHistoryOutput,
    NewsItem
)
import os
from datetime import datetime
from cozeloop.decorator import observe
import json
from jinja2 import Template


def split_emails_node(state: SplitEmailsInput, config: RunnableConfig, runtime: Runtime[Context]) -> SplitEmailsOutput:
    """
    title: åˆ†å‰²é‚®ç®±åœ°å€
    desc: å°†é€—å·åˆ†éš”çš„é‚®ç®±å­—ç¬¦ä¸²åˆ†å‰²æˆåˆ—è¡¨ï¼Œæ”¯æŒé€—å·ã€åˆ†å·ã€ç©ºæ ¼ç­‰åˆ†éš”ç¬¦
    """
    # å°†emailså­—ç¬¦ä¸²åˆ†å‰²æˆåˆ—è¡¨ï¼ˆæ”¯æŒé€—å·ã€åˆ†å·ã€ç©ºæ ¼åˆ†éš”ï¼‰
    emails_str = state.emails or ""
    emails_list = [email.strip() for email in emails_str.replace(';', ',').replace(' ', ',').split(',') if email.strip()]
    
    print(f"åˆ†å‰²åçš„é‚®ç®±åˆ—è¡¨: {emails_list}")
    
    return SplitEmailsOutput(emails_list=emails_list)


def fetch_news_node(state: FetchNewsInput, config: RunnableConfig, runtime: Runtime[Context]) -> FetchNewsOutput:
    """
    title: è·å–æŒ‡å®šæ¥æºæ–°é—»
    desc: ä»ä»Šæ—¥å¤´æ¡ã€æœç‹ã€è…¾è®¯ç½‘ã€ç½‘æ˜“æ–°é—»ã€å‡¤å‡°ç½‘ã€æ–°æµªã€æ–°æµªè´¢ç»ã€æ¾æ¹ƒç½‘ã€ç¯çƒåŒ»ç–—å™¨æ¢°ç½‘ã€36æ°ªåˆ›æŠ•å¹³å°è·å–åŒ»ç–—å™¨æ¢°å’ŒåŒ»ç¾ç›¸å…³çš„æ–°é—»
    integrations: è”ç½‘æœç´¢
    """
    ctx = runtime.context
    
    print("=" * 60)
    print("å¼€å§‹æ‰§è¡Œ fetch_news_node - è·å–æ–°é—»")
    print("=" * 60)
    
    # å¯¼å…¥ç½‘ç»œæœç´¢å‡½æ•°
    from tools.web_search_tool import web_search
    
    # æ£€æŸ¥ç¯å¢ƒå˜é‡
    api_key = os.getenv("COZE_WORKLOAD_IDENTITY_API_KEY")
    base_url = os.getenv("COZE_INTEGRATION_BASE_URL")
    
    print(f"ç¯å¢ƒå˜é‡æ£€æŸ¥:")
    print(f"  API Key: {'âœ… å·²é…ç½®' if api_key else 'âŒ æœªé…ç½®'}")
    print(f"  Base URL: {'âœ… å·²é…ç½®' if base_url else 'âŒ æœªé…ç½®'}")
    if base_url:
        print(f"  Base URL å€¼: {base_url}")
    
    if not api_key or not base_url:
        error_msg = "ç¼ºå°‘å¿…è¦çš„ç¯å¢ƒå˜é‡ï¼šCOZE_WORKLOAD_IDENTITY_API_KEY æˆ– COZE_INTEGRATION_BASE_URL"
        print(f"âŒ é”™è¯¯: {error_msg}")
        raise Exception(error_msg)
    
    news_list = []
    
    # å®šä¹‰ç›®æ ‡æ–°é—»æ¥æºåŸŸåï¼ˆåŸæœ‰ + æ–°å¢ï¼‰
    # æ³¨æ„ï¼šæœç´¢APIé™åˆ¶æœ€å¤š5ä¸ªåŸŸåï¼Œè¿™é‡Œåˆ†æ‰¹æœç´¢
    target_sites_batch1 = "toutiao.com|sohu.com|qq.com|163.com|ifeng.com"
    target_sites_batch2 = "sina.com.cn|thepaper.cn|36kr.com"
    target_sites_batch3 = "ylqx.qgyyzs.net|finance.sina.com.cn"
    
    # æ„å»ºæ ¸å¿ƒæœç´¢è¯åˆ—è¡¨ï¼ˆç¡®ä¿è·å–çš„æ–°é—»ä¸»ä½“å†…å®¹ä¸åŒ»ç–—å™¨æ¢°ã€åŒ»ç¾ç›¸å…³ï¼‰
    # ç¬¬ä¸€æ‰¹æ¬¡æŸ¥è¯¢ï¼ˆå¯¹åº”åŸæœ‰5ä¸ªç½‘ç«™ï¼‰
    batch1_queries = [
        "åŒ»ç–—å™¨æ¢°å…¬å¸",
        "åŒ»ç–—å™¨æ¢°äº§å“",
        "åŒ»ç–—å™¨æ¢°æŠ€æœ¯",
        "åŒ»ç¾å…¬å¸",
        "åŒ»ç¾äº§å“",
        "åŒ»ç¾æŠ€æœ¯"
    ]
    
    # ç¬¬äºŒæ‰¹æ¬¡æŸ¥è¯¢ï¼ˆå¯¹åº”æ–°æµªã€æ¾æ¹ƒç½‘ã€36æ°ªï¼‰
    batch2_queries = [
        "åŒ»ç–—è®¾å¤‡",
        "è¯Šæ–­è®¾å¤‡",
        "æ¿€å…‰ç¾å®¹",
        "æ•´å½¢ç¾å®¹",
        "å¾®æ•´å½¢"
    ]
    
    # ç¬¬ä¸‰æ‰¹æ¬¡æŸ¥è¯¢ï¼ˆå¯¹åº”ç¯çƒåŒ»ç–—å™¨æ¢°ç½‘ã€æ–°æµªè´¢ç»ï¼‰
    batch3_queries = [
        "IVD ä½“å¤–è¯Šæ–­",
        "åŒ»ç–—å™¨æ¢°èèµ„",
        "åŒ»ç–—å™¨æ¢°ä¸Šå¸‚",
        "åŒ»ç¾èèµ„",
        "åŒ»ç¾ä¸Šå¸‚"
    ]
    
    try:
        # åˆ†æ‰¹æœç´¢ï¼Œæ¯æ‰¹å¯¹åº”ä¸åŒçš„ç½‘ç«™
        all_web_items = []
        search_success_count = 0
        search_fail_count = 0
        
        print(f"å¼€å§‹æœç´¢æ–°é—»ï¼Œç¬¬ä¸€æ‰¹æ¬¡ç½‘ç«™: {target_sites_batch1}")
        
        # ç¬¬ä¸€æ‰¹æ¬¡ï¼šåŸæœ‰5ä¸ªç½‘ç«™
        for idx, query in enumerate(batch1_queries, 1):
            try:
                print(f"\n[æ‰¹æ¬¡1-{idx}/{len(batch1_queries)}] å¼€å§‹æœç´¢: '{query}'")
                print(f"  ç›®æ ‡ç½‘ç«™: {target_sites_batch1}")
                
                web_items, _, _, _ = web_search(
                    ctx=ctx,
                    query=query,
                    search_type="web",
                    count=10,
                    need_summary=True,
                    need_content=True,
                    sites=target_sites_batch1
                )
                
                print(f"  âœ… æˆåŠŸè·å–åˆ° {len(web_items)} æ¡æ–°é—»")
                for item in web_items[:3]:  # åªæ‰“å°å‰3æ¡ï¼Œé¿å…æ—¥å¿—è¿‡é•¿
                    print(f"     - {item.Title[:50]}...")
                if len(web_items) > 3:
                    print(f"     ... è¿˜æœ‰ {len(web_items)-3} æ¡")
                
                all_web_items.extend(web_items)
                search_success_count += 1
                
            except Exception as e:
                search_fail_count += 1
                print(f"  âŒ æœç´¢å¤±è´¥: {str(e)}")
                print(f"     é”™è¯¯ç±»å‹: {type(e).__name__}")
                import traceback
                print(f"     è¯¦ç»†é”™è¯¯:\n{traceback.format_exc()}")
                continue
        
        print(f"å¼€å§‹æœç´¢æ–°é—»ï¼Œç¬¬äºŒæ‰¹æ¬¡ç½‘ç«™: {target_sites_batch2}")
        
        # ç¬¬äºŒæ‰¹æ¬¡ï¼šæ–°å¢ç½‘ç«™ï¼ˆæ–°æµªã€æ¾æ¹ƒç½‘ã€36æ°ªï¼‰
        for idx, query in enumerate(batch2_queries, 1):
            try:
                print(f"\n[æ‰¹æ¬¡2-{idx}/{len(batch2_queries)}] å¼€å§‹æœç´¢: '{query}'")
                print(f"  ç›®æ ‡ç½‘ç«™: {target_sites_batch2}")
                
                web_items, _, _, _ = web_search(
                    ctx=ctx,
                    query=query,
                    search_type="web",
                    count=10,
                    need_summary=True,
                    need_content=True,
                    sites=target_sites_batch2
                )
                
                print(f"  âœ… æˆåŠŸè·å–åˆ° {len(web_items)} æ¡æ–°é—»")
                if len(web_items) > 0:
                    print(f"     - {web_items[0].Title[:50]}...")
                
                all_web_items.extend(web_items)
                search_success_count += 1
                
            except Exception as e:
                search_fail_count += 1
                print(f"  âŒ æœç´¢å¤±è´¥: {str(e)}")
                continue
        
        print(f"å¼€å§‹æœç´¢æ–°é—»ï¼Œç¬¬ä¸‰æ‰¹æ¬¡ç½‘ç«™: {target_sites_batch3}")
        
        # ç¬¬ä¸‰æ‰¹æ¬¡ï¼šæ–°å¢ç½‘ç«™ï¼ˆç¯çƒåŒ»ç–—å™¨æ¢°ç½‘ã€æ–°æµªè´¢ç»ï¼‰
        for idx, query in enumerate(batch3_queries, 1):
            try:
                print(f"\n[æ‰¹æ¬¡3-{idx}/{len(batch3_queries)}] å¼€å§‹æœç´¢: '{query}'")
                print(f"  ç›®æ ‡ç½‘ç«™: {target_sites_batch3}")
                
                web_items, _, _, _ = web_search(
                    ctx=ctx,
                    query=query,
                    search_type="web",
                    count=10,
                    need_summary=True,
                    need_content=True,
                    sites=target_sites_batch3
                )
                
                print(f"  âœ… æˆåŠŸè·å–åˆ° {len(web_items)} æ¡æ–°é—»")
                if len(web_items) > 0:
                    print(f"     - {web_items[0].Title[:50]}...")
                
                all_web_items.extend(web_items)
                search_success_count += 1
                
            except Exception as e:
                search_fail_count += 1
                print(f"  âŒ æœç´¢å¤±è´¥: {str(e)}")
                continue
        
        print(f"\n{'='*60}")
        print(f"æœç´¢å®Œæˆç»Ÿè®¡:")
        print(f"  æˆåŠŸ: {search_success_count} ä¸ªæŸ¥è¯¢")
        print(f"  å¤±è´¥: {search_fail_count} ä¸ªæŸ¥è¯¢")
        print(f"  åŸå§‹æ–°é—»æ€»æ•°: {len(all_web_items)} æ¡")
        print(f"{'='*60}")
        
        # å¦‚æœæ²¡æœ‰è·å–åˆ°ä»»ä½•æ–°é—»ï¼Œæ‰“å°è­¦å‘Š
        if not all_web_items:
            print("\nâš ï¸ è­¦å‘Š: æ‰€æœ‰æœç´¢æŸ¥è¯¢éƒ½æ²¡æœ‰è·å–åˆ°æ–°é—»ï¼")
            print("å¯èƒ½çš„åŸå› :")
            print("  1. ç½‘ç»œæœç´¢æœåŠ¡æš‚æ—¶ä¸å¯ç”¨")
            print("  2. ç›®æ ‡ç½‘ç«™æ²¡æœ‰ç›¸å…³æ–°é—»")
            print("  3. æœç´¢è¯éœ€è¦è°ƒæ•´")
            print("  4. API Key æˆ– Base URL é…ç½®é”™è¯¯")
        
        # è½¬æ¢ä¸ºNewsItemæ ¼å¼
        for item in all_web_items:
            if not item.Url:
                continue
            
            # è§£ææ—¥æœŸï¼Œå¦‚æœPublishTimeä¸ºç©ºåˆ™ä½¿ç”¨å½“å‰æ—¥æœŸ
            if item.PublishTime:
                try:
                    # ISOæ—¶é—´æ ¼å¼è½¬æ¢ä¸ºç®€å•æ—¥æœŸ
                    publish_date = item.PublishTime.split('T')[0]
                except:
                    publish_date = datetime.now().strftime('%Y-%m-%d')
            else:
                publish_date = datetime.now().strftime('%Y-%m-%d')
            
            news_item = NewsItem(
                title=item.Title or "",
                date=publish_date,
                url=item.Url,
                summary=item.Snippet or "",
                content=item.Content or "",
                keywords=[]
            )
            news_list.append(news_item)
        
        # å»é‡é€»è¾‘
        # 1. æ ¹æ®URLå»é‡
        seen_urls = set()
        unique_by_url = []
        for news in news_list:
            if news.url not in seen_urls:
                seen_urls.add(news.url)
                unique_by_url.append(news)
        
        # 2. æ ¹æ®æ ‡é¢˜ç›¸ä¼¼åº¦å»é‡ï¼ˆé¿å…ä¸åŒç½‘ç«™çš„ç›¸åŒæ–°é—»ï¼‰
        seen_titles = set()
        final_news = []
        for news in unique_by_url:
            # æ ‡å‡†åŒ–æ ‡é¢˜ï¼šå»é™¤ç©ºæ ¼å’Œç‰¹æ®Šå­—ç¬¦ï¼Œè½¬å°å†™
            normalized_title = news.title.lower().strip()
            # ç§»é™¤ä¸€äº›å¸¸è§çš„ç½‘ç«™åç§°åç¼€
            for suffix in ['| toutiao', '- ä»Šæ—¥å¤´æ¡', '_å¤´æ¡', '_æ–°é—»', '_èµ„è®¯']:
                normalized_title = normalized_title.replace(suffix.lower(), '')
            
            if normalized_title not in seen_titles:
                seen_titles.add(normalized_title)
                final_news.append(news)
        
        print(f"\n{'='*60}")
        print(f"æ–°é—»å»é‡åç»Ÿè®¡:")
        print(f"  å»é‡å‰: {len(news_list)} æ¡")
        print(f"  URLå»é‡å: {len(unique_by_url)} æ¡")
        print(f"  æ ‡é¢˜å»é‡å: {len(final_news)} æ¡")
        print(f"{'='*60}")
        
        if final_news:
            print(f"\nâœ… æœ€ç»ˆè¿”å› {len(final_news)} æ¡æ–°é—»:")
            for idx, news in enumerate(final_news[:5], 1):  # åªæ‰“å°å‰5æ¡
                print(f"  {idx}. [{news.date}] {news.title[:60]}...")
            if len(final_news) > 5:
                print(f"  ... è¿˜æœ‰ {len(final_news)-5} æ¡æ–°é—»")
        else:
            print(f"\nâŒ æœ€ç»ˆæ²¡æœ‰è¿”å›ä»»ä½•æ–°é—»")
        
        print(f"\n{'='*60}")
        print("fetch_news_node æ‰§è¡Œå®Œæˆ")
        print(f"{'='*60}\n")
        
        return FetchNewsOutput(news_list=final_news)
        
    except Exception as e:
        raise Exception(f"è·å–æ–°é—»å¤±è´¥: {str(e)}")


def deduplicate_news_node(state: DeduplicateNewsInput, config: RunnableConfig, runtime: Runtime[Context]) -> DeduplicateNewsOutput:
    """
    title: å»é‡å†å²æ–°é—»
    desc: æŸ¥è¯¢æ•°æ®åº“ä¸­çš„å†å²æ–°é—»è®°å½•ï¼Œå»é™¤é‡å¤çš„æ–°é—»ï¼ˆURLæˆ–æ ‡é¢˜ç›¸åŒçš„æ–°é—»ï¼‰
    integrations: æ•°æ®åº“
    """
    ctx = runtime.context
    
    try:
        from storage.database.db import get_session
        from storage.database.news_history_manager import NewsHistoryManager
        
        # è·å–æ•°æ®åº“ä¼šè¯
        db = get_session()
        
        try:
            # åˆ›å»ºç®¡ç†å™¨
            mgr = NewsHistoryManager()
            
            # è·å–æ‰€æœ‰å†å²æ–°é—»çš„URLå’Œæ ‡é¢˜
            history_urls = mgr.get_all_urls(db)
            history_titles = mgr.get_all_titles(db)
            
            print(f"å†å²è®°å½•ä¸­å…±æœ‰ {len(history_urls)} ä¸ªURLï¼Œ{len(history_titles)} ä¸ªæ ‡é¢˜")
            
            # å»é‡é€»è¾‘
            deduplicated_news = []
            duplicate_count = 0
            
            for news in state.filtered_news_list:
                # 1. æ£€æŸ¥URLæ˜¯å¦å·²å­˜åœ¨
                if news.url in history_urls:
                    duplicate_count += 1
                    print(f"URLé‡å¤ï¼Œè·³è¿‡: {news.title}")
                    continue
                
                # 2. æ£€æŸ¥æ ‡é¢˜æ˜¯å¦å·²å­˜åœ¨
                if news.title in history_titles:
                    duplicate_count += 1
                    print(f"æ ‡é¢˜é‡å¤ï¼Œè·³è¿‡: {news.title}")
                    continue
                
                # é€šè¿‡å»é‡æ£€æŸ¥
                deduplicated_news.append(news)
            
            print(f"å»é‡å®Œæˆ: åŸå§‹ {len(state.filtered_news_list)} æ¡ï¼Œå»é‡ {duplicate_count} æ¡ï¼Œå‰©ä½™ {len(deduplicated_news)} æ¡")
            
            # å¦‚æœå»é‡åæ²¡æœ‰æ–°é—»ï¼Œæ‰“å°è­¦å‘Š
            if not deduplicated_news:
                print("è­¦å‘Š: å»é‡åæ²¡æœ‰å‰©ä½™çš„æ–°é—»ï¼")
            
            return DeduplicateNewsOutput(deduplicated_news_list=deduplicated_news)
            
        finally:
            db.close()
            
    except Exception as e:
        print(f"å»é‡å¤±è´¥: {str(e)}ï¼Œä½¿ç”¨åŸå§‹æ–°é—»åˆ—è¡¨")
        # å¦‚æœå»é‡å¤±è´¥ï¼Œè¿”å›åŸå§‹æ–°é—»åˆ—è¡¨ï¼ˆä¿å®ˆå¤„ç†ï¼‰
        return DeduplicateNewsOutput(deduplicated_news_list=state.filtered_news_list)


def enrich_news_node(state: EnrichNewsInput, config: RunnableConfig, runtime: Runtime[Context]) -> EnrichNewsOutput:
    """
    title: ä¸°å¯Œæ–°é—»ä¿¡æ¯
    desc: ä½¿ç”¨å¤§è¯­è¨€æ¨¡å‹åŒæ—¶ç”Ÿæˆæ–°é—»æ‘˜è¦ã€æå–å…³é”®è¯ã€æ¥æºå’Œåœ°åŒºä¿¡æ¯
    integrations: å¤§è¯­è¨€æ¨¡å‹
    """
    ctx = runtime.context
    
    # æ£€æŸ¥æ˜¯å¦ä¸ºç©ºåˆ—è¡¨
    if not state.deduplicated_news_list:
        print("æ–°é—»åˆ—è¡¨ä¸ºç©ºï¼Œè·³è¿‡æ–°é—»ä¸°å¯Œ")
        return EnrichNewsOutput(enriched_news_list=[])
    
    # è¯»å–é…ç½®æ–‡ä»¶
    cfg_file = os.path.join(os.getenv("COZE_WORKSPACE_PATH"), config['metadata']['llm_cfg'])
    with open(cfg_file, 'r') as fd:
        _cfg = json.load(fd)
    
    llm_config = _cfg.get("config", {})
    system_prompt = _cfg.get("sp", "")
    user_prompt_template = _cfg.get("up", "")
    
    # å¯¼å…¥å¤§è¯­è¨€æ¨¡å‹è°ƒç”¨
    from langchain_openai import ChatOpenAI
    from langchain_core.messages import SystemMessage, HumanMessage, BaseMessageChunk
    from coze_coding_utils.runtime_ctx.context import default_headers
    
    api_key = os.getenv("COZE_WORKLOAD_IDENTITY_API_KEY")
    base_url = os.getenv("COZE_INTEGRATION_MODEL_BASE_URL")
    
    enriched_news = []
    
    for news in state.deduplicated_news_list:
        try:
            # æ¸²æŸ“ç”¨æˆ·æç¤ºè¯
            up_tpl = Template(user_prompt_template)
            user_prompt = up_tpl.render({
                "title": news.title,
                "content": news.content
            })
            
            # è°ƒç”¨å¤§è¯­è¨€æ¨¡å‹
            llm = ChatOpenAI(
                model=llm_config.get("model", "doubao-seed-1-6-251015"),
                api_key=api_key,
                base_url=base_url,
                streaming=True,
                extra_body={
                    "thinking": {
                        "type": "disabled"
                    }
                },
                temperature=llm_config.get("temperature", 0.5),
                max_tokens=llm_config.get("max_tokens", 800),
                default_headers=default_headers(ctx),
            )
            
            messages = [
                SystemMessage(content=system_prompt),
                HumanMessage(content=user_prompt)
            ]
            
            # æ”¶é›†æµå¼è¾“å‡º
            result_text = ""
            for chunk in llm.stream(messages):
                if isinstance(chunk.content, str):
                    result_text += chunk.content
                elif isinstance(chunk.content, list):
                    for item in chunk.content:
                        if isinstance(item, str):
                            result_text += item
            
            # è§£æç»“æœ - å°è¯•æå–JSONæ ¼å¼çš„æ‘˜è¦ã€æ¥æºã€åœ°åŒºå’Œå…³é”®è¯
            try:
                import re
                
                # æ–¹æ³•1: å°è¯•ç›´æ¥è§£ææ•´ä¸ªæ–‡æœ¬ä¸ºJSON
                result_json = None
                try:
                    result_json = json.loads(result_text.strip())
                except:
                    pass
                
                # æ–¹æ³•2: å¦‚æœç›´æ¥è§£æå¤±è´¥ï¼Œä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼æå–JSONå¯¹è±¡
                if not result_json:
                    # æŸ¥æ‰¾ç¬¬ä¸€ä¸ªå®Œæ•´çš„JSONå¯¹è±¡ï¼ˆæ”¯æŒè·¨è¡Œï¼‰
                    json_match = re.search(r'\{[^{}]*(?:\{[^{}]*\}[^{}]*)*\}', result_text, re.DOTALL)
                    if json_match:
                        try:
                            result_json = json.loads(json_match.group())
                        except:
                            pass
                
                # æ–¹æ³•3: å°è¯•åŒ¹é…åŒ…å«æ‰€æœ‰å­—æ®µçš„JSON
                if not result_json:
                    json_match = re.search(r'\{[^}]*"summary"[^}]*"source"[^}]*"region"[^}]*"keywords"[^}]*\}', result_text, re.DOTALL)
                    if json_match:
                        try:
                            result_json = json.loads(json_match.group())
                        except:
                            pass
                
                # æå–å­—æ®µ
                if result_json and isinstance(result_json, dict):
                    summary = result_json.get("summary", news.summary)
                    source = result_json.get("source", "")
                    region = result_json.get("region", "")
                    keywords = result_json.get("keywords", [])
                    
                    # ç¡®ä¿keywordsæ˜¯åˆ—è¡¨
                    if not isinstance(keywords, list):
                        if isinstance(keywords, str):
                            keywords = [k.strip() for k in keywords.split(',') if k.strip()]
                        else:
                            keywords = []
                else:
                    # æ‰€æœ‰æ–¹æ³•éƒ½å¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤å€¼
                    summary = news.summary
                    source = ""
                    region = ""
                    keywords = []
                    
            except Exception as e:
                print(f"è§£æJSONå¤±è´¥: {str(e)}, ä½¿ç”¨é»˜è®¤å€¼")
                summary = news.summary
                source = ""
                region = ""
                keywords = []
            
            # æ›´æ–°æ–°é—»é¡¹
            news.summary = summary
            news.source = source
            news.region = region
            news.keywords = keywords
            enriched_news.append(news)
            
        except Exception as e:
            # å¦‚æœä¸°å¯Œå¤±è´¥ï¼Œä¿ç•™åŸå§‹æ–°é—»
            print(f"ä¸°å¯Œæ–°é—»å¤±è´¥: {str(e)}, ä¿ç•™åŸå§‹æ–°é—»")
            enriched_news.append(news)
    
    return EnrichNewsOutput(enriched_news_list=enriched_news)


def extract_date_node(state: ExtractDateInput, config: RunnableConfig, runtime: Runtime[Context]) -> ExtractDateOutput:
    """
    title: æå–å¹¶è¿‡æ»¤æ–°é—»æ—¥æœŸ
    desc: ç›´æ¥ä½¿ç”¨ç½‘ç»œæœç´¢è¿”å›çš„æ—¥æœŸå­—æ®µï¼Œåªä¿ç•™è¿‘3ä¸ªæœˆå†…çš„æ–°é—»
    """
    # æ£€æŸ¥æ˜¯å¦ä¸ºç©ºåˆ—è¡¨
    if not state.news_list:
        print("æ–°é—»åˆ—è¡¨ä¸ºç©ºï¼Œè·³è¿‡æ—¥æœŸè¿‡æ»¤")
        return ExtractDateOutput(filtered_news_list=[])
    
    # è®¡ç®—è¿‘3ä¸ªæœˆçš„æˆªæ­¢æ—¥æœŸ
    from datetime import timedelta
    today = datetime.now()
    three_months_ago = today - timedelta(days=90)
    cutoff_date_str = three_months_ago.strftime('%Y-%m-%d')
    
    print(f"æ—¥æœŸè¿‡æ»¤æˆªæ­¢æ—¥æœŸ: {cutoff_date_str}")
    
    filtered_news = []
    no_date_count = 0
    old_date_count = 0
    
    for news in state.news_list:
        try:
            # ç›´æ¥ä½¿ç”¨å·²æœ‰çš„æ—¥æœŸå­—æ®µ
            news_date = news.date if news.date else ""
            
            # å¦‚æœæ²¡æœ‰æ—¥æœŸï¼Œä½¿ç”¨å½“å‰æ—¥æœŸï¼ˆä¿å®ˆå¤„ç†ï¼‰
            if not news_date:
                news_date = today.strftime('%Y-%m-%d')
                no_date_count += 1
                print(f"æ–°é—»æ— æ—¥æœŸï¼Œä½¿ç”¨å½“å‰æ—¥æœŸ: {news.title}")
            
            # æ£€æŸ¥æ—¥æœŸæ ¼å¼æ˜¯å¦ä¸º YYYY-MM-DD
            import re
            if not re.match(r'^\d{4}-\d{2}-\d{2}$', news_date):
                print(f"æ—¥æœŸæ ¼å¼æ— æ•ˆï¼Œè·³è¿‡: {news.title}, æ—¥æœŸ: {news_date}")
                continue
            
            # åˆ¤æ–­æ—¥æœŸæ˜¯å¦åœ¨è¿‘3ä¸ªæœˆå†…
            if news_date >= cutoff_date_str:
                # æ›´æ–°æ–°é—»çš„æ—¥æœŸå­—æ®µï¼ˆç¡®ä¿æ ¼å¼æ­£ç¡®ï¼‰
                news.date = news_date
                filtered_news.append(news)
            else:
                old_date_count += 1
                print(f"æ–°é—»å·²è¿‡æ»¤ï¼ˆæ—¥æœŸè¿‡æ—©ï¼‰: {news.title}, æ—¥æœŸ: {news_date}")
            
        except Exception as e:
            # å¦‚æœå¤„ç†å¤±è´¥ï¼Œè·³è¿‡è¯¥æ–°é—»
            print(f"å¤„ç†æ—¥æœŸå¤±è´¥: {str(e)}, è·³è¿‡æ–°é—»: {news.title}")
            continue
    
    print(f"æ—¥æœŸè¿‡æ»¤å®Œæˆ: åŸå§‹ {len(state.news_list)} æ¡ï¼Œæ— æ—¥æœŸ {no_date_count} æ¡ï¼Œè¿‡æœŸ {old_date_count} æ¡ï¼Œä¿ç•™ {len(filtered_news)} æ¡")
    
    return ExtractDateOutput(filtered_news_list=filtered_news)


def create_table_node(state: CreateTableInput, config: RunnableConfig, runtime: Runtime[Context]) -> CreateTableOutput:
    """
    title: åˆ›å»ºæ–°é—»è¡¨æ ¼
    desc: å°†æ–°é—»æ•°æ®åˆ›å»ºä¸ºExcelè¡¨æ ¼æ–‡ä»¶
    """
    ctx = runtime.context
    
    try:
        import pandas as pd
        from datetime import datetime
        import os
        
        print(f"æ”¶åˆ° {len(state.enriched_news_list)} æ¡æ–°é—»")
        if not state.enriched_news_list:
            print("è­¦å‘Šï¼šæ²¡æœ‰æ–°é—»éœ€è¦åˆ›å»ºè¡¨æ ¼")
            # åˆ›å»ºä¸€ä¸ªç©ºçš„è¡¨æ ¼ï¼ŒåŒ…å«è¡¨å¤´
            empty_data = {
                "æ ‡é¢˜": [],
                "æ—¥æœŸ": [],
                "æ¥æº": [],
                "åœ°åŒº": [],
                "å…³é”®è¯": [],
                "é“¾æ¥": [],
                "æ‘˜è¦": []
            }
            df = pd.DataFrame(empty_data)
            
            today = datetime.now().strftime("%Y%m%d")
            filename = f"æ–°é—»æ±‡æ€»_{today}.xlsx"
            filepath = f"/tmp/{filename}"
            
            df.to_excel(filepath, index=False, engine='openpyxl')
            
            return CreateTableOutput(
                enriched_news_list=[],
                synced_count=0,
                table_filepath=filepath,
                table_filename=filename
            )
        
        # å‡†å¤‡æ•°æ®
        table_data = []
        for news in state.enriched_news_list:
            keywords_str = ", ".join(news.keywords) if news.keywords else ""
            table_data.append({
                "æ ‡é¢˜": news.title,
                "æ—¥æœŸ": news.date,
                "æ¥æº": news.source,
                "åœ°åŒº": news.region,
                "å…³é”®è¯": keywords_str,
                "é“¾æ¥": news.url,
                "æ‘˜è¦": news.summary
            })
        
        # åˆ›å»ºDataFrame
        df = pd.DataFrame(table_data)
        
        # ç”Ÿæˆæ–‡ä»¶åï¼ˆåŒ…å«æ—¥æœŸï¼‰
        today = datetime.now().strftime("%Y%m%d")
        filename = f"æ–°é—»æ±‡æ€»_{today}.xlsx"
        filepath = f"/tmp/{filename}"
        
        # ä¿å­˜ä¸ºExcelæ–‡ä»¶
        df.to_excel(filepath, index=False, engine='openpyxl')
        
        print(f"Excelè¡¨æ ¼å·²åˆ›å»º: {filepath}")
        
        # å°†æ–‡ä»¶è·¯å¾„å­˜å‚¨åœ¨å…¨å±€çŠ¶æ€ä¸­ï¼Œä¾›é‚®ä»¶èŠ‚ç‚¹ä½¿ç”¨
        # é€šè¿‡ä¿®æ”¹å…¨å±€çŠ¶æ€å®ç°
        # è¿™é‡Œæˆ‘ä»¬è¿”å›æ–‡ä»¶è·¯å¾„ï¼Œé€šè¿‡å…¨å±€çŠ¶æ€ä¼ é€’
        
        return CreateTableOutput(
            enriched_news_list=state.enriched_news_list,
            synced_count=len(state.enriched_news_list),
            table_filepath=filepath,
            table_filename=filename
        )
        
    except Exception as e:
        raise Exception(f"åˆ›å»ºè¡¨æ ¼å¤±è´¥: {str(e)}")


def send_email_node(state: SendEmailInput, config: RunnableConfig, runtime: Runtime[Context]) -> SendEmailOutput:
    """
    title: å‘é€é‚®ä»¶é€šçŸ¥
    desc: å°†æ–°é—»æ±‡æ€»ä¿¡æ¯å’ŒExcelè¡¨æ ¼é™„ä»¶å‘é€åˆ°æŒ‡å®šé‚®ç®±
    integrations: é‚®ä»¶
    """
    ctx = runtime.context
    
    try:
        # å¯¼å…¥é‚®ä»¶ç›¸å…³æ¨¡å—
        import smtplib
        import ssl
        import os
        from email.mime.multipart import MIMEMultipart
        from email.mime.text import MIMEText
        from email.mime.base import MIMEBase
        from email import encoders
        from email.header import Header
        from email.utils import formataddr, formatdate, make_msgid
        from coze_workload_identity import Client
        
        # è·å–é‚®ä»¶é…ç½®
        client = Client()
        email_credential = client.get_integration_credential("integration-email-imap-smtp")
        email_config = json.loads(email_credential)
        
        print(f"é‚®ä»¶é…ç½®: {email_config.get('account')}")
        print(f"æ”¶ä»¶äººåˆ—è¡¨: {state.emails_list}")
        print(f"æ–°é—»æ•°é‡: {len(state.enriched_news_list)}")
        
        # æ£€æŸ¥æ˜¯å¦æœ‰æ–°é—»æ•°æ®
        has_news = len(state.enriched_news_list) > 0
        
        if not has_news:
            print("âš ï¸ æ²¡æœ‰æ–°é—»æ•°æ®ï¼Œå°†å‘é€é€šçŸ¥é‚®ä»¶")
        
        # æ„å»ºé‚®ä»¶å†…å®¹ï¼ˆHTMLæ ¼å¼ï¼‰
        from datetime import datetime
        today = datetime.now().strftime("%Y-%m-%d")
        
        if has_news:
            # æœ‰æ–°é—»æ—¶ï¼Œæ„å»ºå¸¦æ–°é—»åˆ—è¡¨çš„é‚®ä»¶
            # æ£€æŸ¥è¡¨æ ¼æ–‡ä»¶æ˜¯å¦å­˜åœ¨
            print(f"è¡¨æ ¼æ–‡ä»¶è·¯å¾„: {state.table_filepath}")
            print(f"è¡¨æ ¼æ–‡ä»¶å­˜åœ¨: {os.path.exists(state.table_filepath) if state.table_filepath else False}")
            
            if not state.table_filepath or not os.path.exists(state.table_filepath):
                print("âŒ ä¸å‘é€é‚®ä»¶: è¡¨æ ¼æ–‡ä»¶ä¸å­˜åœ¨")
                return SendEmailOutput(
                    email_sent=False,
                    email_message=f"è¡¨æ ¼æ–‡ä»¶ä¸å­˜åœ¨: {state.table_filepath}"
                )
            
            html_content = f"""
            <html>
            <head>
                <style>
                    body {{ font-family: Arial, sans-serif; line-height: 1.6; color: #333; }}
                    .container {{ max-width: 800px; margin: 0 auto; padding: 20px; }}
                    .header {{ background-color: #4CAF50; color: white; padding: 20px; text-align: center; }}
                    .summary {{ background-color: #f8f8f8; padding: 15px; border-radius: 5px; margin: 20px 0; }}
                    .attachment-note {{ background-color: #fff3cd; border: 1px solid #ffeeba; padding: 15px; border-radius: 5px; margin: 20px 0; text-align: center; }}
                    .news-item {{ border: 1px solid #ddd; padding: 15px; margin: 10px 0; border-radius: 5px; }}
                    .news-item:hover {{ box-shadow: 0 2px 5px rgba(0,0,0,0.1); }}
                    .news-title {{ font-size: 18px; font-weight: bold; margin-bottom: 10px; color: #2c3e50; }}
                    .news-meta {{ color: #666; font-size: 14px; margin-bottom: 10px; }}
                    .news-summary {{ margin-bottom: 10px; }}
                    .news-keywords {{ color: #e74c3c; font-size: 14px; }}
                    .news-link {{ color: #3498db; text-decoration: none; }}
                    .news-link:hover {{ text-decoration: underline; }}
                    .footer {{ text-align: center; margin-top: 30px; color: #999; font-size: 12px; }}
                </style>
            </head>
            <body>
                <div class="container">
                    <div class="header">
                        <h2>åŒ»ç–—å™¨æ¢°åŒ»ç¾æ–°é—»æ±‡æ€»</h2>
                        <p>æ—¥æœŸ: {today}</p>
                    </div>
                    
                    <div class="attachment-note">
                        <p><strong>ğŸ“ è¯¦ç»†æ•°æ®å·²ä½œä¸ºé™„ä»¶å‘é€</strong></p>
                        <p>é™„ä»¶æ–‡ä»¶: {state.table_filename}</p>
                        <p>åŒ…å« {len(state.enriched_news_list)} æ¡æ–°é—»è®°å½•</p>
                    </div>
                    
                    <div class="summary">
                        <p><strong>å…±æ”¶é›†åˆ° {len(state.enriched_news_list)} æ¡ç›¸å…³æ–°é—»</strong></p>
                        <p>æ¥æº: ç½‘ç»œæœé›†</p>
                    </div>
            """
            
            # æ·»åŠ æ¯æ¡æ–°é—»
            for idx, news in enumerate(state.enriched_news_list, 1):
                keywords_str = ", ".join(news.keywords) if news.keywords else "æ— "
                source_str = news.source if news.source else "æœªçŸ¥"
                region_str = news.region if news.region else "-"
                html_content += f"""
                <div class="news-item">
                    <div class="news-title">{idx}. {news.title}</div>
                    <div class="news-meta">
                        <strong>æ—¥æœŸ:</strong> {news.date} |
                        <strong>æ¥æº:</strong> {source_str} |
                        <strong>åœ°åŒº:</strong> {region_str} |
                        <strong>å…³é”®è¯:</strong> <span class="news-keywords">{keywords_str}</span>
                    </div>
                    <div class="news-summary">
                        <strong>æ‘˜è¦:</strong> {news.summary}
                    </div>
                    <div>
                        <a href="{news.url}" class="news-link">æŸ¥çœ‹åŸæ–‡ &rarr;</a>
                    </div>
                </div>
            """
            
            html_content += f"""
                    <div class="footer">
                        <p>æ­¤é‚®ä»¶ç”±æ–°é—»æ”¶é›†åŠ©æ‰‹è‡ªåŠ¨å‘é€</p>
                        <p>å¦‚æœ‰é—®é¢˜ï¼Œè¯·è”ç³»ç®¡ç†å‘˜</p>
                    </div>
                </div>
            </body>
            </html>
            """
            
            # è¯»å–Excelæ–‡ä»¶å†…å®¹
            with open(state.table_filepath, 'rb') as f:
                file_content = f.read()
        else:
            # æ²¡æœ‰æ–°é—»æ—¶ï¼Œæ„å»ºé€šçŸ¥é‚®ä»¶
            html_content = f"""
            <html>
            <head>
                <style>
                    body {{ font-family: Arial, sans-serif; line-height: 1.6; color: #333; }}
                    .container {{ max-width: 800px; margin: 0 auto; padding: 20px; }}
                    .header {{ background-color: #ff9800; color: white; padding: 20px; text-align: center; }}
                    .notice {{ background-color: #fff3cd; border: 1px solid #ffeeba; padding: 20px; border-radius: 5px; margin: 20px 0; }}
                    .footer {{ text-align: center; margin-top: 30px; color: #999; font-size: 12px; }}
                </style>
            </head>
            <body>
                <div class="container">
                    <div class="header">
                        <h2>åŒ»ç–—å™¨æ¢°åŒ»ç¾æ–°é—»æ±‡æ€»</h2>
                        <p>æ—¥æœŸ: {today}</p>
                    </div>
                    
                    <div class="notice">
                        <h3>âš ï¸ ä»Šæ—¥æœªæ”¶é›†åˆ°æ–°æ–°é—»</h3>
                        <p>å¯èƒ½çš„åŸå› ï¼š</p>
                        <ul>
                            <li>ä»Šæ—¥æ— åŒ»ç–—å™¨æ¢°æˆ–åŒ»ç¾ç›¸å…³æ–°é—»</li>
                            <li>æ‰€æœ‰æ–°é—»å·²åœ¨ä¹‹å‰å‘é€è¿‡ï¼ˆå·²å»é‡ï¼‰</li>
                            <li>ç½‘ç»œæœç´¢æœåŠ¡æš‚æ—¶ä¸å¯ç”¨</li>
                        </ul>
                        <p><strong>å·¥ä½œæµå·²æ­£å¸¸è¿è¡Œï¼Œè¯·å‹¿æ‹…å¿ƒã€‚</strong></p>
                        <p>å»ºè®®ï¼šæ˜å¤©å†æ£€æŸ¥ä¸€æ¬¡ï¼Œæˆ–è”ç³»ç®¡ç†å‘˜ã€‚</p>
                    </div>
                    
                    <div class="footer">
                        <p>æ­¤é‚®ä»¶ç”±æ–°é—»æ”¶é›†åŠ©æ‰‹è‡ªåŠ¨å‘é€</p>
                        <p>å¦‚æœ‰é—®é¢˜ï¼Œè¯·è”ç³»ç®¡ç†å‘˜</p>
                    </div>
                </div>
            </body>
            </html>
            """
        
        # åˆ†åˆ«å‘é€ç»™æ¯ä¸ªæ”¶ä»¶äºº
        success_count = 0
        failed_emails = []
        
        # ä¸ºæ¯ä¸ªæ”¶ä»¶äººå•ç‹¬å‘é€é‚®ä»¶
        for idx, recipient_email in enumerate(state.emails_list):
            try:
                # åˆ¤æ–­æ˜¯å¦ä¸ºç¬¬ä¸€ä¸ªæ”¶ä»¶äºº
                is_first_recipient = (idx == 0)
                
                # åˆ›å»ºé‚®ä»¶
                if has_news:
                    # æœ‰æ–°é—»æ—¶
                    if is_first_recipient:
                        # ç¬¬ä¸€ä¸ªæ”¶ä»¶äººï¼šå‘é€å¸¦é™„ä»¶çš„é‚®ä»¶ï¼ˆHTML + é™„ä»¶ï¼‰
                        print(f"ğŸ“ å‘é€å¸¦é™„ä»¶çš„é‚®ä»¶åˆ°ç¬¬ä¸€ä¸ªæ”¶ä»¶äºº: {recipient_email}")
                        msg = MIMEMultipart()
                        msg["From"] = formataddr(("æ–°é—»æ”¶é›†åŠ©æ‰‹", email_config["account"]))
                        msg["To"] = recipient_email  # åªæ˜¾ç¤ºä¸€ä¸ªæ”¶ä»¶åœ°å€
                        msg["Subject"] = Header(f"åŒ»ç–—å™¨æ¢°åŒ»ç¾æ–°é—»æ±‡æ€» - {today}", 'utf-8')
                        msg["Date"] = formatdate(localtime=True)
                        msg["Message-ID"] = make_msgid()
                        
                        # æ·»åŠ HTMLæ­£æ–‡
                        msg.attach(MIMEText(html_content, 'html', 'utf-8'))
                        
                        # æ·»åŠ Excelé™„ä»¶
                        part = MIMEBase('application', 'octet-stream')
                        part.set_payload(file_content)
                        
                        encoders.encode_base64(part)
                        part.add_header(
                            'Content-Disposition',
                            f'attachment; filename="{Header(state.table_filename, "utf-8").encode()}'
                        )
                        msg.attach(part)
                    else:
                        # åç»­æ”¶ä»¶äººï¼šåªå‘é€HTMLå†…å®¹ï¼ˆä¸å«é™„ä»¶ï¼‰
                        print(f"ğŸ“§ å‘é€æ— é™„ä»¶çš„é‚®ä»¶åˆ°åç»­æ”¶ä»¶äºº: {recipient_email}")
                        msg = MIMEText(html_content, 'html', 'utf-8')
                        msg["From"] = formataddr(("æ–°é—»æ”¶é›†åŠ©æ‰‹", email_config["account"]))
                        msg["To"] = recipient_email
                        msg["Subject"] = Header(f"åŒ»ç–—å™¨æ¢°åŒ»ç¾æ–°é—»æ±‡æ€» - {today}", 'utf-8')
                        msg["Date"] = formatdate(localtime=True)
                        msg["Message-ID"] = make_msgid()
                else:
                    # æ²¡æœ‰æ–°é—»æ—¶ï¼Œåªå‘é€HTMLé€šçŸ¥é‚®ä»¶
                    msg = MIMEText(html_content, 'html', 'utf-8')
                    msg["From"] = formataddr(("æ–°é—»æ”¶é›†åŠ©æ‰‹", email_config["account"]))
                    msg["To"] = recipient_email
                    msg["Subject"] = Header(f"æ–°é—»æ±‡æ€» - {today}ï¼ˆæ— æ–°æ–°é—»ï¼‰", 'utf-8')
                    msg["Date"] = formatdate(localtime=True)
                    msg["Message-ID"] = make_msgid()
                
                # å‘é€é‚®ä»¶
                ctx_ssl = ssl.create_default_context()
                ctx_ssl.minimum_version = ssl.TLSVersion.TLSv1_2
                
                with smtplib.SMTP_SSL(
                    email_config["smtp_server"],
                    email_config["smtp_port"],
                    context=ctx_ssl,
                    timeout=30
                ) as server:
                    server.ehlo()
                    server.login(email_config["account"], email_config["auth_code"])
                    # åªå‘é€ç»™å½“å‰æ”¶ä»¶äºº
                    server.sendmail(email_config["account"], [recipient_email], msg.as_string())
                    server.quit()
                
                success_count += 1
                if is_first_recipient and has_news:
                    print(f"âœ… é‚®ä»¶ï¼ˆå«é™„ä»¶ï¼‰å·²æˆåŠŸå‘é€åˆ°: {recipient_email}")
                else:
                    print(f"âœ… é‚®ä»¶ï¼ˆæ— é™„ä»¶ï¼‰å·²æˆåŠŸå‘é€åˆ°: {recipient_email}")
                
            except Exception as e:
                print(f"âŒ å‘é€åˆ° {recipient_email} å¤±è´¥: {str(e)}")
                failed_emails.append(f"{recipient_email}: {str(e)}")
        
        # è¿”å›å‘é€ç»“æœ
        if success_count > 0:
            if failed_emails:
                message = f"é‚®ä»¶å·²æˆåŠŸå‘é€åˆ° {success_count} ä¸ªæ”¶ä»¶äººã€‚å¤±è´¥çš„é‚®ç®±: {', '.join(failed_emails)}"
            else:
                if has_news:
                    # ç¬¬ä¸€ä¸ªæ”¶ä»¶äººæ”¶åˆ°é™„ä»¶ï¼Œåç»­åªæ”¶åˆ°HTMLå†…å®¹
                    if success_count > 1:
                        message = f"é‚®ä»¶å·²æˆåŠŸå‘é€åˆ°æ‰€æœ‰ {success_count} ä¸ªæ”¶ä»¶äººã€‚ç¬¬ä¸€ä¸ªé‚®ç®±å«Excelé™„ä»¶ï¼Œåç»­{success_count-1}ä¸ªé‚®ç®±ä»…å«HTMLå†…å®¹"
                    else:
                        message = f"é‚®ä»¶å·²æˆåŠŸå‘é€åˆ°å”¯ä¸€æ”¶ä»¶äººï¼ŒåŒ…å« {len(state.enriched_news_list)} æ¡æ–°é—»åŠExcelé™„ä»¶"
                else:
                    message = f"å·²æˆåŠŸå‘é€é€šçŸ¥é‚®ä»¶åˆ°æ‰€æœ‰ {success_count} ä¸ªæ”¶ä»¶äººï¼ˆä»Šæ—¥æ— æ–°æ–°é—»ï¼‰"
            return SendEmailOutput(
                email_sent=True,
                email_message=message
            )
        else:
            return SendEmailOutput(
                email_sent=False,
                email_message=f"é‚®ä»¶å‘é€å¤±è´¥: {', '.join(failed_emails)}"
            )
        
    except smtplib.SMTPAuthenticationError as e:
        return SendEmailOutput(
            email_sent=False,
            email_message=f"é‚®ä»¶è®¤è¯å¤±è´¥: {str(e)}"
        )
    except smtplib.SMTPRecipientsRefused as e:
        return SendEmailOutput(
            email_sent=False,
            email_message=f"æ”¶ä»¶äººåœ°å€è¢«æ‹’ç»"
        )
    except Exception as e:
        return SendEmailOutput(
            email_sent=False,
            email_message=f"å‘é€é‚®ä»¶å¤±è´¥: {str(e)}"
        )


def save_news_history_node(state: SaveNewsHistoryInput, config: RunnableConfig, runtime: Runtime[Context]) -> SaveNewsHistoryOutput:
    """
    title: ä¿å­˜æ–°é—»å†å²è®°å½•
    desc: å°†å·²å‘é€çš„æ–°é—»ä¿å­˜åˆ°æ•°æ®åº“ï¼Œç”¨äºåç»­å»é‡
    integrations: æ•°æ®åº“
    """
    ctx = runtime.context
    
    # æ£€æŸ¥æ˜¯å¦ä¸ºç©ºåˆ—è¡¨
    if not state.enriched_news_list:
        print("æ–°é—»åˆ—è¡¨ä¸ºç©ºï¼Œæ— éœ€ä¿å­˜å†å²è®°å½•")
        return SaveNewsHistoryOutput(
            saved_count=0,
            message="æ–°é—»åˆ—è¡¨ä¸ºç©ºï¼Œæ— éœ€ä¿å­˜å†å²è®°å½•"
        )
    
    try:
        from storage.database.db import get_session
        from storage.database.news_history_manager import NewsHistoryManager, NewsHistoryCreate
        
        # è·å–æ•°æ®åº“ä¼šè¯
        db = get_session()
        
        try:
            # åˆ›å»ºç®¡ç†å™¨
            mgr = NewsHistoryManager()
            
            # å‡†å¤‡æ‰¹é‡åˆ›å»ºçš„æ•°æ®
            news_history_list = []
            for news in state.enriched_news_list:
                news_create = NewsHistoryCreate(
                    title=news.title,
                    url=news.url,
                    date=news.date,
                    source=news.source
                )
                news_history_list.append(news_create)
            
            # æ‰¹é‡ä¿å­˜åˆ°æ•°æ®åº“
            saved_records = mgr.batch_create_news_history(db, news_history_list)
            
            saved_count = len(saved_records)
            print(f"æˆåŠŸä¿å­˜ {saved_count} æ¡æ–°é—»å†å²è®°å½•")
            
            # æ¸…ç†æ—§æ•°æ®ï¼ˆåˆ é™¤180å¤©ä¹‹å‰çš„è®°å½•ï¼‰
            try:
                deleted_count = mgr.delete_old_news(db, days=180)
                if deleted_count > 0:
                    print(f"æ¸…ç†äº† {deleted_count} æ¡180å¤©å‰çš„å†å²è®°å½•")
            except Exception as e:
                print(f"æ¸…ç†å†å²è®°å½•å¤±è´¥: {str(e)}")
            
            return SaveNewsHistoryOutput(
                saved_count=saved_count,
                message=f"æˆåŠŸä¿å­˜ {saved_count} æ¡æ–°é—»å†å²è®°å½•"
            )
            
        finally:
            db.close()
            
    except Exception as e:
        raise Exception(f"ä¿å­˜æ–°é—»å†å²è®°å½•å¤±è´¥: {str(e)}")
